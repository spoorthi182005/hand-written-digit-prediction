{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQf/uR+frG97dCrBiBbNOy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spoorthi182005/hand-written-digit-prediction/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hand Written Digit Prediction**\n",
        "\n",
        "**Objective**\n",
        "\n",
        "The objective of hand-written digit prediction is to develop a machine learning model that accurately identifies and classifies handwritten digits (0-9) from images. This task is crucial for applications such as optical character recognition (OCR), digitization of documents, and automated form processing."
      ],
      "metadata": {
        "id": "Y_KI2HDMqpuo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Source**\n",
        "\n",
        "Handwritten digit prediction typically involves using machine learning algorithms, such as convolutional neural networks (CNNs), trained on datasets like MNIST or USPS, which consist of labeled images of handwritten digits. These algorithms learn to classify new images of handwritten digits based on patterns and features extracted from the training data.\n",
        "\n",
        "**Import Library**\n"
      ],
      "metadata": {
        "id": "KmIOJ1NLrLjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n"
      ],
      "metadata": {
        "id": "c8OLrhFMrUXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import DataSet**"
      ],
      "metadata": {
        "id": "hQcs0ie8rcuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize the pixel values to be between 0 and 1\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Print the shapes of the datasets\n",
        "print(\"Training data shape:\", x_train.shape)  # (60000, 28, 28) - 60000 samples of 28x28 images\n",
        "print(\"Training labels shape:\", y_train.shape)  # (60000,) - 60000 labels (one for each image)\n",
        "\n",
        "print(\"Test data shape:\", x_test.shape)  # (10000, 28, 28) - 10000 samples of 28x28 images\n",
        "print(\"Test labels shape:\", y_test.shape)  # (10000,) - 10000 labels (one for each image)\n"
      ],
      "metadata": {
        "id": "Wjxh1BH-rhj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Describe Data**\n"
      ],
      "metadata": {
        "id": "o4X7v7p9roSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load and preprocess data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "X_train = X_train.reshape(-1, 28, 28, 1)\n",
        "X_test = X_test.reshape(-1, 28, 28, 1)\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "# Build the model\n",
        "model = Sequential([\n",
        "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f'Test accuracy: {test_acc}')\n",
        "\n"
      ],
      "metadata": {
        "id": "TzJD8_CUrsnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Visualization**\n"
      ],
      "metadata": {
        "id": "XOhOujyXrz3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "\n",
        "# Load the digits dataset\n",
        "digits = datasets.load_digits()\n",
        "\n",
        "# Create a figure to display the digits\n",
        "fig = plt.figure(figsize=(8, 8))\n",
        "\n",
        "# Plot several digits\n",
        "for i in range(10):\n",
        "    ax = fig.add_subplot(2, 5, i + 1)\n",
        "    ax.matshow(digits.images[i], cmap='gray_r')\n",
        "    plt.title(f\"Digit: {digits.target[i]}\")\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "ISHo5SWqr8EA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Preprocessing**\n"
      ],
      "metadata": {
        "id": "5m4UwWcssUSd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist  # If using TensorFlow\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize the pixel values to be between 0 and 1\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0\n",
        "\n",
        "# Flatten the images from 28x28 to 784-dimensional vectors\n",
        "X_train = X_train.reshape((X_train.shape[0], 28*28))\n",
        "X_test = X_test.reshape((X_test.shape[0], 28*28))\n",
        "\n",
        "# Print the shape of the data for verification\n",
        "print('X_train shape:', X_train.shape)\n",
        "print('X_test shape:', X_test.shape)\n",
        "print('y_train shape:', y_train.shape)\n",
        "print('y_test shape:', y_test.shape)\n"
      ],
      "metadata": {
        "id": "yqXXCfXnsV9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Target Variable (y) and Feature Variables (X)**"
      ],
      "metadata": {
        "id": "5MzTVgiHsdYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "# Load the MNIST dataset (or any similar dataset)\n",
        "mnist = fetch_openml('mnist_784', version=1)\n",
        "X, y = mnist.data, mnist.target\n",
        "\n",
        "# Print the shapes of X and y\n",
        "print(\"Shape of X:\", X.shape)  # Shape of X: (70000, 784) -> 70000 samples, 784 features (pixels)\n",
        "print(\"Shape of y:\", y.shape)  # Shape of y: (70000,) -> 70000 labels (digits)\n",
        "\n",
        "# Optionally, you can normalize the pixel values to be between 0 and 1\n",
        "X = X / 255.0\n"
      ],
      "metadata": {
        "id": "URrGVgZ3slLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Test SplitTrain**\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "436CWvQOspX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "digits = load_digits()\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Print the shapes of the training and testing sets\n",
        "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
        "print(\"Testing set shape:\", X_test.shape, y_test.shape)\n"
      ],
      "metadata": {
        "id": "gUh3ZiqLstCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Modeling**\n",
        "\n"
      ],
      "metadata": {
        "id": "Oc1oZ2hWsyZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, datasets\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Define the model architecture\n",
        "model = models.Sequential([\n",
        "    layers.Flatten(input_shape=(28, 28)),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f\"Test accuracy: {test_acc}\")\n",
        "\n",
        "# Plot training history\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RX21f5A0s2q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Evaluation**\n",
        "\n"
      ],
      "metadata": {
        "id": "8Sqyltf3s82F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Assuming you have your predictions and true labels\n",
        "y_true = np.array([3, 8, 1, 0, 7])  # Example true labels\n",
        "y_pred = np.array([3, 8, 1, 1, 7])  # Example predicted labels\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_true, y_pred)\n",
        "print('Classification Report:\\n', report)\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "3reZDb_ktFKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prediction**\n"
      ],
      "metadata": {
        "id": "2j-O_SM6tPyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Build the model\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print('\\nTest accuracy:', test_acc)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(x_test[:5])\n",
        "predicted_labels = [tf.argmax(prediction).numpy() for prediction in predictions]\n",
        "\n",
        "print('Predicted labels:', predicted_labels)\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "KVhOskWWtUZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation**\n"
      ],
      "metadata": {
        "id": "rtLqOuwltekB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handwritten digit prediction showcases the capability of machine learning algorithms to interpret and classify complex data. With advancements in deep learning and neural networks, particularly CNNs, accuracy rates have improved significantly, often surpassing human-level performance on standard datasets like MNIST. This task not only demonstrates the power of modern machine learning but also has practical applications in various industries where automated recognition of handwritten digits is beneficial."
      ],
      "metadata": {
        "id": "iiLz0AxGtlno"
      }
    }
  ]
}